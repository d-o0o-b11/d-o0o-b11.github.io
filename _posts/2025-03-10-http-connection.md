---
title: HTTP , HTTPS 동작 원리 [5]
description: HTTP 커넥션 관리
# author: d_o0o_b
categories: [Dev-Notes, Theory]
tags: [typography]
# pin: true
math: true
mermaid: true
---

## 개요
HTTP는 클라이언트와 서버 간 통신을 위해 주로 TCP를 전송 프로토콜로 사용합니다. 초기 HTTP 모델에서는 요청이 발생할 때마다 새로운 TCP 연결을 생성하고 응답을 받은 후 연결을 즉시 닫는 방식이었습니다. 이러한 방식은 단순하지만 매 요청마다 새로운 연결을 생성하는 과정에서 성능 저하가 발생하는 문제가 있었습니다.

TCP 연결을 설정하는 과정은 네트워크 지연과 대역폭 소비를 초래합니다. 특히 현대 웹페이지는 다양한 리소스를 로드하기 위해 다수의 요청을 필요로 하므로 기존의 비효율적인 연결 방식으로는 성능이 크게 저하될 수밖에 없습니다.

이를 개선하기 위해 HTTP/1.1에서는 두 가지 주요 기능이 도입되었습니다.

1. 영속적인 커넥션(Persistent Connection)
<br/>
요청과 응답이 완료된 후에도 TCP 연결을 유지하여 추가 요청 시 새로운 연결을 생성하는 비용을 절감할 수 있도록 했습니다.

2. HTTP 파이프라이닝(Pipelining) 
<br/>
응답을 기다리지 않고 여러 개의 요청을 연속적으로 전송하여 네트워크 지연을 최소화했습니다.


## HTTP의 커넥션 관리 방식
HTTP에서 커넥션을 관리할 때 **end-to-end(종단 간, 처음부터 끝까지)** 방식이 아니라 **hop-by-hop(각 단계별)** 방식을 사용합니다.
- end-to-end 방식
<br/>
    클라이언트와 최종 목적지(서버)까지 하나의 연결을 유지하는 방식
- hop-by-hop 방식
<br/>
    클라이언트와 중간 프록시(proxy) 간의 연결, 프록시와 서버 간의 연결 등 각 단계에서 연결을 따로 관리하는 방식

### 정리
클라이언트와 서버가 직접 연결된 것이 아니라, 프록시 같은 중간 노드를 거치는 경우가 많다!
<br/>
각 연결(클라이언트 ↔ 프록시, 프록시 ↔ 서버)은 각각 따로 유지될 수 있고 서로 다른 방식으로 동작할 수도 있다!

### hop-by-hop 방식의 예시
> 클라이언트가 웹사이트에 접속할 때 프록시 서버를 거쳐야 하는 상황

- 클라이언트 ↔ 프록시: HTTP/1.1의 Keep-Alive를 이용해 연결을 유지할 수 있음
- 프록시 ↔ 서버: HTTP/2를 이용해 멀티플렉싱으로 여러 개의 요청을 처리할 수도 있음

!! 클라이언트와 프록시 간의 연결 방식과 프록시와 서버 간의 연결 방식이 다를 수 있다는 것!
→ 각각의 단계(hop)에서 연결이 따로 관리되고 있다는 뜻입니다.


## 단기 커넥션 (Short-lived Connection)
HTTP/1.0의 기본 방식으로 각각의 HTTP 요청이 새로운 TCP 연결을 생성하는 방식입니다.
<br/>
→ 요청을 보낼 때마다 TCP 핸드셰이크(TCP 연결 설정 과정)가 필요합니다. 응답이 끝나면 즉시 연결을 닫습니다.

### 문제점
1. TCP 핸드셰이크 오버헤드 
<br/>
→ 요청마다 새 연결을 만들기 때문에 시간이 많이 걸립니다.

2. TCP 성능 최적화 불가능 
<br/>
→ 지속적인 연결 유지가 없어서 TCP의 효율적인 데이터 전송(예열 효과)을 활용할 수 없습니다.
<br/>
연결이 계속 새로 만들어지므로 성능 저하 발생

### 사용되는 경우
- HTTP/1.0의 기본 모델
<br/>
    HTTP/1.0에서는 특별한 설정이 없으면 기본적으로 단기 커넥션을 사용합니다.
- HTTP/1.1에서도 `Connection: close` 헤더가 설정된 경우
<br/>
    기본적으로 HTTP/1.1은 **영속적인 커넥션(persistent connection)**을 사용하지만
    `Connection: close` 헤더를 명시하면 단기 커넥션 방식이 적용됩니다.

### 정리
- 단기 커넥션 = 요청마다 새로운 TCP 연결을 만드는 방식
- 단점: TCP 핸드셰이크가 매번 발생해 성능이 떨어집니다.
- HTTP/1.0 기본 모델이며 HTTP/1.1에서도 `Connection: close`를 사용하면 적용됩니다.
<br/>
위 문제를 해결하기 위해 HTTP/1.1에서는 기본적으로 '영속적인 커넥션'을 사용합니다.


## 영속적인 커넥션(Persistent Connection) 
한 번 TCP 연결을 맺으면 여러 개의 요청을 그 연결에서 재사용하는 방식입니다.
새로운 요청마다 TCP 핸드셰이크를 반복하는 단기 커넥션의 단점을 보완한 모델이며 Keep-Alive 커넥션이라고도 불립니다.

### 사용되는 경우
- HTTP/1.1에서는 기본적으로 영속적인 커넥션을 사용합니다.
- 일정 시간 동안 요청이 없으면 연결을 자동으로 종료합니다. (Keep-Alive 타이머 설정 가능)
- 서버는 Keep-Alive 헤더를 사용해 연결 유지 시간을 설정할 수 있습니다.
- `Connection: close` 헤더를 명시하면 단기 커넥션으로 동작합니다.


### 장점
- TCP 핸드셰이크 비용 절감 
<br/>
→ 요청마다 새 연결을 만드는 대신 기존 연결을 유지하며 사용합니다.

- TCP 성능 향상 
<br/>
→ 연결을 유지하면 TCP가 최적화되어 데이터 전송 속도가 빨라집니다.

### 단점
- 서버 리소스가 소모됩니다.
<br/>
→ 연결이 열려 있는 동안 서버가 메모리와 CPU를 사용해야 합니다.

- 과부하 & DoS 공격 위험 
<br/>
→ 너무 많은 연결이 유지되면 서버 부하가 증가합니다.

### 정리
- 영속적인 커넥션 = 한 번 맺은 연결을 여러 요청에 재사용
- 장점: 성능 향상, 네트워크 비용 절감
- 단점: 서버 리소스 사용 증가, 과부하 위험
- HTTP/1.1에서는 기본적으로 영속적인 커넥션 사용 (별도 설정 없이 자동)


## HTTP 파이프라이닝

### 기존 HTTP 요청 방식
원래 HTTP 요청은 순차적으로 처리됩니다. 이전 요청에 대한 응답을 받아야 다음 요청을 보낼 수 있습니다.
하지만 이렇게 하면 네트워크 지연 때문에 시간이 오래 걸립니다.
- A 요청 → 응답 받음 → B 요청 → 응답 받음

### 파이프라이닝(Pipelining)
응답을 기다리지 않고 연속적으로 요청을 보내는 방식입니다.
네트워크 대기 시간을 줄여서 속도를 높일 수 있습니다.
- A 요청 → B 요청 → 응답 받음 → 응답 받음

### 한계점
> 왜 모던 브라우저에서는 기본적으로 비활성화되어 있을까?

1. 버그 있는 프록시(Proxy)들이 많다.

중간에 있는 프록시가 파이프라이닝을 제대로 지원하지 않아서 오류 발생,
예측 불가능한 버그 때문에 웹 개발자들이 문제를 해결하기 어려움

2. HOL(Head-of-Line) 문제

앞에 있는 요청이 지연되면 뒤에 있는 요청도 함께 지연됩니다.
이런 문제 때문에 HTTP/2에서는 더 나은 기술인 **멀티플렉싱(Multiplexing)**을 도입하였습니다.

### 사용하지 않는다.
HTTP/1.1에서는 응답을 기다리지 않고 요청을 보내는 방식이지만 제대로 동작하지 않는 경우가 많습니다.
이런 문제들 때문에 모던 브라우저는 기본적으로 비활성화했음.
대신 HTTP/2의 멀티플렉싱이 등장하면서 파이프라이닝을 더 이상 사용할 필요가 없어졌습니다.


## HTTP/2 멀티플렉싱(Multiplexing) 

### HTTP/1.1의 문제점 <HOL(Head-of-Line) 블로킹>
기본적으로 하나의 TCP 연결에서 한 번에 하나의 요청만 처리 가능합니다.
파이프라이닝을 사용해도 앞 요청이 지연되면 뒤 요청도 같이 지연됩니다. → HOL 문제 발생

```
HTML 요청 (0.5초)
CSS 요청 (0.1초)
JS 요청 (0.3초)

=> HTML 응답이 늦어지면, CSS, JS도 같이 지연
```

### HTTP/2 멀티플렉싱
하나의 TCP 연결에서 여러 개의 요청과 응답을 동시에 처리 가능합니다.

```
HTML 요청 (0.5초)
CSS 요청 (0.1초)
JS 요청 (0.3초)

=> 각 요청이 개별적으로 처리되어 CSS, JS가 HTML을 기다릴 필요 없다.
```

### 성능을 높이는 이유
1. 병렬 처리 (Parallel Processing)
<br/>
HTTP/1.1 → 한 번에 하나씩 요청 처리
<br/>
HTTP/2 → 여러 요청을 한꺼번에 처리

2. TCP 연결 감소
<br/>
HTTP/1.1에서는 속도 문제를 해결하려고 여러 개의 TCP 연결을 만듦
하지만 TCP 연결을 많이 만들면 오히려 속도가 느려짐
<br/>
HTTP/2에서는 하나의 TCP 연결에서 모든 요청을 처리하므로 효율적!

3. HOL 문제 해결
<br/>
앞 요청이 느려도 뒷 요청이 기다릴 필요 없다

4. 헤더 압축 (HPACK)
<br/>
HTTP/1.1에서는 요청할 때마다 같은 헤더 정보(쿠키, 에이전트 정보 등)를 계속 전송해야 했다.
<br/>
HTTP/2에서는 헤더를 압축해서 네트워크 부하를 줄임



## 왜?
### 연결을 유지하면 TCP가 최적화되어 데이터 전송 속도가 왜 빨라지는걸까?

1. TCP 연결이 유지되면 뭐가 달라질까?
<br/>
TCP는 데이터를 전송할 때 단순히 패킷을 보내는 것이 아니라 **네트워크 상태를 학습**하고 **최적화하는 과정**을 거칩니다. 이 과정이 끝나면 전송 속도가 빨라지는데 연결을 끊었다가 다시 맺으면 이 최적화 과정이 처음부터 다시 시작됩니다.
<br/>
연결을 유지하면 TCP가 더 효율적으로 동작할 수 있는 상태를 유지하면서 데이터 전송 속도가 점점 빨라지는 효과를 얻을 수 있습니다.

2. TCP 최적화가 이루어지는 과정
<br/>
① **TCP 혼잡 제어 (Congestion Control)**
<br/>
TCP는 처음 데이터를 보낼 때 네트워크 상태를 모릅니다.
그래서 처음에는 작은 데이터 크기(Congestion Window, CWND)로 전송하고 점점 크기를 늘려 나갑니다.
연결이 유지되면 이미 학습된 네트워크 상태를 활용할 수 있어 빠르게 큰 데이터를 보낼 수 있습니다!
하지만 연결을 끊었다가 다시 맺으면 이 과정이 처음부터 다시 시작되어 느려집니다.
<br/>
<br/>
② **TCP 슬로우 스타트 (Slow Start) & 패킷 손실 방지**
<br/>
TCP는 처음엔 천천히 데이터를 전송하며 네트워크가 얼마나 많은 데이터를 감당할 수 있는지 학습합니다.
연결이 유지되면 이미 이 정보가 남아 있어서 바로 최적 속도로 데이터 전송 가능합니다.
하지만 새 연결을 만들면 다시 처음부터 작은 데이터 크기로 시작해야 해서 속도가 떨어집니다.
<br/>
<br/>
③ **TCP Keep-Alive & 재전송 비용 절감**
<br/>
만약 연결이 유지되면 TCP가 이미 열린 상태를 유지하면서 데이터 전송을 계속할 수 있습니다.
반대로 연결이 끊기면 다시 3-way Handshake 과정을 거쳐야 해서 지연이 발생합니다.

3. 실제 성능 차이

- 영속적 연결 (Persistent Connection) 사용 시
<br/>
TCP는 학습된 상태를 유지하면서 데이터를 더 빠르게 보낼 수 있습니다.
<br/>
연결 유지 비용보다 새로운 연결을 만드는 비용이 더 크기 때문에 성능이 향상됩니다.
<br/>

```
for i in {1..10}; do curl -s -w "Time taken for request: %{time_total}\n" --http2 --header "Connection: keep-alive" https://사이트; done
-> 10번 이상 반복해서 요청을 보내고 평균 응답 시간 계산

```
![Image](https://github.com/user-attachments/assets/a10f7430-9b70-41f7-8991-4f6a47d55be0?raw=true)

- 단기 연결 (Short-lived Connection) 사용 시
<br/>
매번 새로운 연결을 만들면서 TCP 학습 과정이 초기화됩니다. → 속도 저하
<br/>
3-way Handshake 반복 발생 → 네트워크 부담 증가

```
for i in {1..10}; do curl -s -w "Time taken for request: %{time_total}\n" --http2 --header "Connection: close" https://사이트; done
-> 10번 이상 반복해서 요청을 보내고 평균 응답 시간 계산
```

![Image](https://github.com/user-attachments/assets/932bae90-5c08-456d-a781-7244edc08c8e?raw=true)


### 내가 배포한 웹사이트들은 HTTP 버전 몇을 쓰고 있었던걸까?
이 명령어를 사용하면 HTTP/2, HTTP/1.1 프로토콜을 통해 웹 서버에 요청하고 그 서버의 응답 헤더만 보여줍니다.
```
curl -I -s --http2 https://사이트

curl -I -s --http1.1 https://사이트
```

![Image](https://github.com/user-attachments/assets/11ea2bf6-8f67-4d60-995a-24d5c718a13e?raw=true)

![Image](https://github.com/user-attachments/assets/39b0509e-0f6c-4ae5-aa83-97a0f1123983?raw=true)

=> HTTP/2를 기본으로 사용하지만 클라이언트가 HTTP/2를 지원하지 않으면 자동으로 HTTP/1.1로 연결된다.